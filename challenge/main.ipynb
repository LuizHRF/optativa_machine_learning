{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c92524",
   "metadata": {},
   "source": [
    "# **Classification Challenge**\n",
    "\n",
    "`Tópicos Especiais em Computação VIII`\n",
    "\n",
    "Using Random Forests to predict hospital readmissions of diabetic patients\n",
    "\n",
    "*Luiz Henrique Rigo Faccio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c172efb",
   "metadata": {},
   "source": [
    "## **Importing Libraries and loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading informations\n",
    "folder = \"diabetes\"\n",
    "diabetes = pd.read_csv(f'{folder}/diabetic_data.csv')\n",
    "mapping = pd.read_csv(f'{folder}/IDS_mapping.csv')\n",
    "admission_type_mapping = mapping[0:7]\n",
    "discharge_disposition_mapping = mapping[10:40].reset_index(drop=True)\n",
    "admission_source_mapping = mapping[42:67].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06393241",
   "metadata": {},
   "source": [
    "## **Observing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes.shape)\n",
    "print(diabetes.info())\n",
    "print(diabetes.describe(include='all'))\n",
    "print()\n",
    "for c in diabetes.columns:\n",
    "    print(f\"Column {c}\", end=\"\\n\\t\\t\")\n",
    "    print(diabetes[c].unique(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cd3d1",
   "metadata": {},
   "source": [
    "## **Data treatment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18598361",
   "metadata": {},
   "source": [
    "The `pre_process_diabetes_data()` function can be used to process new information so that it can be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_diabetes_data(df):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            df (pandas DataFrame): Dataset to be processed\n",
    "\n",
    "        Returns:\n",
    "            df (pandas DataFrame): Processed dataset\n",
    "\n",
    "        This function processes diabetes data from the original form to the model-ready form.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Dropping IDs and unnecessary columns and standadizing the missing values\n",
    "\n",
    "    df.drop(columns=['encounter_id', 'patient_nbr', 'payer_code'], inplace=True)\n",
    "    df.replace([\"?\", 'Unknown/Invalid'], pd.NA, inplace=True)\n",
    "\n",
    "    # Also drppping columns with too little information (Mostly null values)\n",
    "    \n",
    "    df.drop(columns=['weight', 'medical_specialty', 'max_glu_serum', 'A1Cresult'], inplace=True)\n",
    "\n",
    "    # Joining tables\n",
    "\n",
    "    df = df.join(admission_type_mapping[\"description\"], how='left', on='admission_type_id').rename(columns={\"description\": \"admission_type\"}).drop(columns=['admission_type_id'])\n",
    "    df = df.join(discharge_disposition_mapping[\"description\"], how='left', on='discharge_disposition_id').rename(columns={\"description\": \"discharge_disposition\"}).drop(columns=['discharge_disposition_id'])\n",
    "    df = df.join(admission_source_mapping[\"description\"], how='left', on='admission_source_id').rename(columns={\"description\": \"admission_source\"}).drop(columns=['admission_source_id'])\n",
    "\n",
    "    # Dropping rows with missing values\n",
    "\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Treating the target \n",
    "\n",
    "    y = df[\"readmitted\"].replace({'NO': 0, '>30': 1, '<30': 2})\n",
    "    df.drop(columns=['readmitted'], inplace=True)\n",
    "\n",
    "    # Scaling numerical variables\n",
    "\n",
    "    numerical_cols =df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Getting dummies for categorical variables \n",
    "\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    temp = pd.DataFrame()\n",
    "    for column in categorical_columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column, dtype=int)\n",
    "        temp = pd.concat([temp, dummies], axis=1)\n",
    "        df.drop(columns=[column], inplace=True)\n",
    "\n",
    "    # Removing columns with low variance\n",
    "    \n",
    "    selector = VarianceThreshold(threshold=0.01)    ## Remove collumns with variance lower than 0.01, that is, those collumns have the same value for 99.9% of the rows\n",
    "    temp = pd.DataFrame(selector.fit_transform(temp), columns=temp.columns[selector.get_support()])\n",
    "\n",
    "    final = pd.concat([df, temp, y], axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d447ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the dataset\n",
    "\n",
    "diabetes_processed = pre_process_diabetes_data(diabetes)\n",
    "diabetes_processed.info(verbose=True, memory_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa183d50",
   "metadata": {},
   "source": [
    "## **The model** \n",
    "\n",
    "Two different models were used: RandomForest and Multi Layer Perceptron Classifier (RNN)\n",
    "\n",
    "Not only a single model was trained, rather, a Grid Serach was executed to find the best combination of parameters for this proble, to each of the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67686939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_Random_Forest(processed_data, target):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            processed_data (pandas DataFrame): Processed diabetes dataset to be used for training\n",
    "            target (str): Target variable name\n",
    "\n",
    "        Returns:\n",
    "            rf (RandomForestClassifier): Trained Random Forest model\n",
    "\n",
    "        This function trains a Random Forest model on the processed diabetes dataset, using predefined hyperparameters.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Splitting the data into train and test sets\n",
    "    X = processed_data.drop(columns=[target])\n",
    "    y = processed_data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Creating and training the Random Forest model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=8,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf.fit(X_train, y_train),\n",
    "    print(f\"Train score: {rf.score(X_test, y_test)}\")\n",
    "\n",
    "    return rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6213711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_RNN(processed_data, target):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            processed_data (pandas DataFrame): Processed diabetes dataset to be used for training\n",
    "            target (str): Target variable name\n",
    "\n",
    "        Returns:\n",
    "            model (MLPClassifier): Trained MLP model\n",
    "\n",
    "        This function trains a Multi-Layer Perceptron (MLP) model on the processed diabetes dataset, using predefined hyperparameters.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Splitting the data into train and test sets\n",
    "    X = processed_data.drop(columns=[target])\n",
    "    y = processed_data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),   \n",
    "        activation='relu',             # ('tanh', 'logistic', etc.)\n",
    "        solver='adam',                 # ('adam', 'sgd', etc.)\n",
    "        max_iter=230,                  \n",
    "        random_state=42,\n",
    "        verbose=True,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=15,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting Data\n",
    "# X = diabetes.drop(columns=['readmitted'])\n",
    "# y = diabetes['readmitted']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],             \n",
    "#     'max_depth': [None, 10, 20, 30],             \n",
    "#     'min_samples_split': [2, 5, 10],             \n",
    "#     'min_samples_leaf': [1, 2, 4],               \n",
    "#     'max_features': ['sqrt', 'log2', None],      \n",
    "#     'bootstrap': [True, False],                  \n",
    "#     'criterion': ['gini', 'entropy']             \n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=10, scoring='f1', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"\\nMelhores parâmetros encontrados:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(\"\\nMelhor score de validação cruzada:\")\n",
    "# cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# print(cv_results_df[['param_criterion', 'param_max_depth', 'param_min_samples_split', 'mean_test_score', 'std_test_score', 'rank_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1899e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = single_model_Random_Forest(diabetes_processed, \"readmitted\")\n",
    "mlp = single_model_RNN(diabetes_processed, \"readmitted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
